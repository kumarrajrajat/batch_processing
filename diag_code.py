# CORRECT VERSION - RTMPose End-to-End Converter 
# Based on diagnostic output: N=2, K=133, simcc_x=(2,133,384), simcc_y=(2,133,512)
# Fixes the reshape tensor size mismatch by maintaining proper element counts

import onnx
from onnx import helper, TensorProto
import numpy as np

class RTMPoseEndToEndConverter:
    """
    CORRECT VERSION - Based on actual model analysis
    Your model outputs: simcc_x(2,133,384), simcc_y(2,133,512)
    This means N=2, K=133, W=384, H=512
    """
    
    def __init__(self, simcc_split_ratio=2.0, model_input_size=(256, 192)):
        self.simcc_split_ratio = simcc_split_ratio
        self.model_input_size = model_input_size
    
    def convert_to_end_to_end(self, backbone_model_path, output_model_path):
        """Convert RTMPose backbone to end-to-end model"""
        
        print("üîÑ Loading RTMPose backbone model...")
        onnx_model = onnx.load(backbone_model_path)
        graph = onnx_model.graph
        
        # Set opset version
        del onnx_model.opset_import[:]
        opset = onnx_model.opset_import.add()
        opset.domain = ""
        opset.version = 11
        
        print("üîÑ Adding SIMCC post-processing nodes...")
        postprocess_nodes = self._create_postprocess_nodes()
        graph.node.extend(postprocess_nodes)
        
        print("üîÑ Adding constants...")
        constants = self._create_constants()
        graph.initializer.extend(constants)
        
        print("üîÑ Updating inputs/outputs...")
        self._add_batch_inputs(graph)
        self._update_outputs(graph)
        
        print("üíæ Saving model...")
        onnx.save(onnx_model, output_model_path)
        
        print(f"‚úÖ Success! Model saved: {output_model_path}")
        print("üìä Model works with:")
        print("   ‚Ä¢ Any batch size (N)")
        print("   ‚Ä¢ 133 keypoints (K=133)")  
        print("   ‚Ä¢ Input: [N,3,H,W], centers[N,2], scales[N,2]")
        print("   ‚Ä¢ Output: keypoints[N,133,2], scores[N,133]")
        
        return output_model_path
    
    def _create_less_or_equal_nodes(self, input_a, input_b, output_name, nodes):
        """Create LessOrEqual equivalent using opset 11 compatible operators"""
        less_node = helper.make_node('Less', [input_a, input_b], [f'{output_name}_less'])
        nodes.append(less_node)
        
        equal_node = helper.make_node('Equal', [input_a, input_b], [f'{output_name}_equal'])
        nodes.append(equal_node)
        
        or_node = helper.make_node('Or', [f'{output_name}_less', f'{output_name}_equal'], [output_name])
        nodes.append(or_node)
        
        return nodes
    
    def _create_postprocess_nodes(self):
        """
        CORRECT VERSION - Based on your model's actual shapes
        simcc_x: [N, 133, 384], simcc_y: [N, 133, 512]
        After flatten: [N*133, 384] and [N*133, 512]
        After ArgMax: [N*133] each
        After stack: [N*133, 2] 
        Final reshape: [N, 133, 2] and [N, 133]
        """
        nodes = []
        
        # === Step 1: Flatten inputs ===
        # [N, 133, 384] -> [N*133, 384]
        simcc_x_flat = helper.make_node('Flatten', ['simcc_x'], ['simcc_x_flat'], axis=1)
        nodes.append(simcc_x_flat)
        
        # [N, 133, 512] -> [N*133, 512]  
        simcc_y_flat = helper.make_node('Flatten', ['simcc_y'], ['simcc_y_flat'], axis=1)
        nodes.append(simcc_y_flat)
        
        # === Step 2: Find peaks (ArgMax + ReduceMax) ===
        # [N*133, 384] -> [N*133] (x coordinates)
        x_locs = helper.make_node('ArgMax', ['simcc_x_flat'], ['x_locs'], axis=1, keepdims=0)
        nodes.append(x_locs)
        
        # [N*133, 512] -> [N*133] (y coordinates)
        y_locs = helper.make_node('ArgMax', ['simcc_y_flat'], ['y_locs'], axis=1, keepdims=0)
        nodes.append(y_locs)
        
        # [N*133, 384] -> [N*133] (max values for confidence)
        max_x = helper.make_node('ReduceMax', ['simcc_x_flat'], ['max_x'], axes=[1], keepdims=0)
        nodes.append(max_x)
        
        # [N*133, 512] -> [N*133] (max values for confidence)
        max_y = helper.make_node('ReduceMax', ['simcc_y_flat'], ['max_y'], axes=[1], keepdims=0)
        nodes.append(max_y)
        
        # === Step 3: Process coordinates ===
        # Convert to float
        x_locs_float = helper.make_node('Cast', ['x_locs'], ['x_locs_float'], to=TensorProto.FLOAT)
        nodes.append(x_locs_float)
        
        y_locs_float = helper.make_node('Cast', ['y_locs'], ['y_locs_float'], to=TensorProto.FLOAT)
        nodes.append(y_locs_float)
        
        # Stack coordinates: [N*133] -> [N*133, 1] -> [N*133, 2]
        x_unsqueeze = helper.make_node('Unsqueeze', ['x_locs_float'], ['x_unsqueeze'], axes=[-1])
        nodes.append(x_unsqueeze)
        
        y_unsqueeze = helper.make_node('Unsqueeze', ['y_locs_float'], ['y_unsqueeze'], axes=[-1])
        nodes.append(y_unsqueeze)
        
        # [N*133, 2] - coordinates
        coords_flat = helper.make_node('Concat', ['x_unsqueeze', 'y_unsqueeze'], ['coords_flat'], axis=-1)
        nodes.append(coords_flat)
        
        # === Step 4: Compute scores ===
        # scores = 0.5 * (max_x + max_y) -> [N*133]
        scores_sum = helper.make_node('Add', ['max_x', 'max_y'], ['scores_sum'])
        nodes.append(scores_sum)
        
        scores_flat = helper.make_node('Mul', ['scores_sum', 'half'], ['scores_flat'])
        nodes.append(scores_flat)
        
        # === Step 5: Apply masking in flat domain ===
        
        # Invalid mask: scores <= 0 -> [N*133] boolean
        self._create_less_or_equal_nodes('scores_flat', 'zero_f', 'invalid_mask', nodes)
        
        # Apply to coordinates: set invalid to -1
        invalid_2d = helper.make_node('Unsqueeze', ['invalid_mask'], ['invalid_2d'], axes=[-1])
        nodes.append(invalid_2d)
        
        # [N*133, 1] -> [N*133, 2]
        invalid_broadcast = helper.make_node('Tile', ['invalid_2d', 'tile_2d'], ['invalid_broadcast'])
        nodes.append(invalid_broadcast)
        
        # Apply mask: [N*133, 2]
        coords_masked = helper.make_node('Where', ['invalid_broadcast', 'minus_one_f', 'coords_flat'], ['coords_masked'])
        nodes.append(coords_masked)
        
        # === Step 6: Failure mask for (x == 0) | (y == 0) ===
        
        # Extract x and y coordinates: [N*133, 2] -> [N*133, 1] each
        coords_x = helper.make_node('Slice', ['coords_masked', 'slice_starts_0', 'slice_ends_1', 'slice_axes_1'], ['coords_x'])
        nodes.append(coords_x)
        
        coords_y = helper.make_node('Slice', ['coords_masked', 'slice_starts_1', 'slice_ends_2', 'slice_axes_1'], ['coords_y'])
        nodes.append(coords_y)
        
        # Create failure masks: [N*133, 1] each
        x_zero_mask = helper.make_node('Equal', ['coords_x', 'zero_f'], ['x_zero_mask'])
        nodes.append(x_zero_mask)
        
        y_zero_mask = helper.make_node('Equal', ['coords_y', 'zero_f'], ['y_zero_mask'])
        nodes.append(y_zero_mask)
        
        # Combine: [N*133, 1]
        failure_mask_2d = helper.make_node('Or', ['x_zero_mask', 'y_zero_mask'], ['failure_mask_2d'])
        nodes.append(failure_mask_2d)
        
        # Apply to coordinates: [N*133, 1] -> [N*133, 2]
        failure_broadcast = helper.make_node('Tile', ['failure_mask_2d', 'tile_2d'], ['failure_broadcast'])
        nodes.append(failure_broadcast)
        
        coords_final_flat = helper.make_node('Where', ['failure_broadcast', 'zero_f', 'coords_masked'], ['coords_final_flat'])
        nodes.append(coords_final_flat)
        
        # Apply to scores: [N*133, 1] -> [N*133]
        failure_1d = helper.make_node('Squeeze', ['failure_mask_2d'], ['failure_1d'], axes=[-1])
        nodes.append(failure_1d)
        
        scores_final_flat = helper.make_node('Where', ['failure_1d', 'zero_f', 'scores_flat'], ['scores_final_flat'])
        nodes.append(scores_final_flat)
        
        # === Step 7: CORRECT RESHAPE (this is where the error was!) ===
        
        # Get original shape to extract N and K
        shape_x = helper.make_node('Shape', ['simcc_x'], ['shape_x'])
        nodes.append(shape_x)
        
        n_dim = helper.make_node('Gather', ['shape_x', 'zero_idx'], ['N'], axis=0)
        nodes.append(n_dim)
        
        k_dim = helper.make_node('Gather', ['shape_x', 'one_idx'], ['K'], axis=0)
        nodes.append(k_dim)
        
        # Build reshape targets
        n_1d = helper.make_node('Unsqueeze', ['N'], ['N_1d'], axes=[0])
        nodes.append(n_1d)
        
        k_1d = helper.make_node('Unsqueeze', ['K'], ['K_1d'], axes=[0])
        nodes.append(k_1d)
        
        # [N, K, 2] shape for coordinates
        nk2_shape = helper.make_node('Concat', ['N_1d', 'K_1d', 'two_1d'], ['nk2_shape'], axis=0)
        nodes.append(nk2_shape)
        
        # [N, K] shape for scores  
        nk_shape = helper.make_node('Concat', ['N_1d', 'K_1d'], ['nk_shape'], axis=0)
        nodes.append(nk_shape)
        
        # *** CRITICAL FIX: These reshapes now work because element counts match! ***
        # coords_final_flat: [N*133, 2] = 266*2 = 532 elements
        # nk2_shape: [N, K, 2] = [2, 133, 2] = 532 elements ‚úì
        coords_reshaped = helper.make_node('Reshape', ['coords_final_flat', 'nk2_shape'], ['coords_reshaped'])
        nodes.append(coords_reshaped)
        
        # scores_final_flat: [N*133] = 266 elements  
        # nk_shape: [N, K] = [2, 133] = 266 elements ‚úì
        scores_reshaped = helper.make_node('Reshape', ['scores_final_flat', 'nk_shape'], ['scores_reshaped'])
        nodes.append(scores_reshaped)
        
        # === Step 8: Coordinate transformations ===
        
        # Normalize by split ratio: coords = coords / simcc_split_ratio
        coords_norm = helper.make_node('Div', ['coords_reshaped', 'split_ratio'], ['coords_norm'])
        nodes.append(coords_norm)
        
        # Scale by input size: coords = coords / input_size * scale
        input_size_2d = helper.make_node('Unsqueeze', ['input_size'], ['input_size_2d'], axes=[0])
        nodes.append(input_size_2d)
        
        coords_div_input = helper.make_node('Div', ['coords_norm', 'input_size_2d'], ['coords_div_input'])
        nodes.append(coords_div_input)
        
        scales_expanded = helper.make_node('Unsqueeze', ['scales'], ['scales_expanded'], axes=[1])
        nodes.append(scales_expanded)
        
        coords_scaled = helper.make_node('Mul', ['coords_div_input', 'scales_expanded'], ['coords_scaled'])
        nodes.append(coords_scaled)
        
        # Add centers and subtract half scale  
        centers_expanded = helper.make_node('Unsqueeze', ['centers'], ['centers_expanded'], axes=[1])
        nodes.append(centers_expanded)
        
        coords_centered = helper.make_node('Add', ['coords_scaled', 'centers_expanded'], ['coords_centered'])
        nodes.append(coords_centered)
        
        scales_half = helper.make_node('Div', ['scales_expanded', 'two_f'], ['scales_half'])
        nodes.append(scales_half)
        
        coords_final = helper.make_node('Sub', ['coords_centered', 'scales_half'], ['coords_final'])
        nodes.append(coords_final)
        
        # === Step 9: Final masking on reshaped tensors ===
        
        # Final invalid mask: scores <= 0 on reshaped tensor [N, K]
        self._create_less_or_equal_nodes('scores_reshaped', 'zero_f', 'final_invalid', nodes)
        
        final_invalid_2d = helper.make_node('Unsqueeze', ['final_invalid'], ['final_invalid_2d'], axes=[-1])
        nodes.append(final_invalid_2d)
        
        # [N, K, 1] -> [N, K, 2]
        final_invalid_broadcast = helper.make_node('Tile', ['final_invalid_2d', 'tile_3d'], ['final_invalid_broadcast'])
        nodes.append(final_invalid_broadcast)
        
        # Apply final mask
        keypoints_final = helper.make_node('Where', ['final_invalid_broadcast', 'minus_one_f', 'coords_final'], ['final_keypoints'])
        nodes.append(keypoints_final)
        
        # Scores output (already masked)
        scores_final = helper.make_node('Identity', ['scores_reshaped'], ['final_scores'])
        nodes.append(scores_final)
        
        return nodes
    
    def _create_constants(self):
        """Create all required constants"""
        constants = []
        
        # Index constants for operations
        constants.append(helper.make_tensor('zero_idx', TensorProto.INT64, [], [0]))
        constants.append(helper.make_tensor('one_idx', TensorProto.INT64, [], [1]))
        constants.append(helper.make_tensor('two_idx', TensorProto.INT64, [], [2]))
        
        # Shape constants
        constants.append(helper.make_tensor('two_1d', TensorProto.INT64, [1], [2]))  # For building [N, K, 2]
        constants.append(helper.make_tensor('tile_2d', TensorProto.INT64, [2], [1, 2]))  # For 2D tile [N*K,1]->[N*K,2]
        constants.append(helper.make_tensor('tile_3d', TensorProto.INT64, [3], [1, 1, 2]))  # For 3D tile [N,K,1]->[N,K,2]
        
        # Slice constants (opset 11 requirement)
        constants.append(helper.make_tensor('slice_starts_0', TensorProto.INT64, [1], [0]))
        constants.append(helper.make_tensor('slice_ends_1', TensorProto.INT64, [1], [1]))
        constants.append(helper.make_tensor('slice_axes_1', TensorProto.INT64, [1], [1]))
        constants.append(helper.make_tensor('slice_starts_1', TensorProto.INT64, [1], [1]))
        constants.append(helper.make_tensor('slice_ends_2', TensorProto.INT64, [1], [2]))
        
        # Float constants
        constants.append(helper.make_tensor('zero_f', TensorProto.FLOAT, [], [0.0]))
        constants.append(helper.make_tensor('half', TensorProto.FLOAT, [], [0.5]))
        constants.append(helper.make_tensor('minus_one_f', TensorProto.FLOAT, [], [-1.0]))
        constants.append(helper.make_tensor('two_f', TensorProto.FLOAT, [], [2.0]))
        
        # Model parameters
        constants.append(helper.make_tensor('split_ratio', TensorProto.FLOAT, [], [self.simcc_split_ratio]))
        constants.append(helper.make_tensor('input_size', TensorProto.FLOAT, [2], 
                                          [float(self.model_input_size[0]), float(self.model_input_size[1])]))
        
        return constants
    
    def _add_batch_inputs(self, graph):
        """Add centers and scales inputs"""
        centers_input = helper.make_tensor_value_info('centers', TensorProto.FLOAT, [None, 2])
        scales_input = helper.make_tensor_value_info('scales', TensorProto.FLOAT, [None, 2])
        graph.input.extend([centers_input, scales_input])
    
    def _update_outputs(self, graph):
        """Update model outputs"""
        del graph.output[:]
        
        # Output shapes: [N, 133, 2] for keypoints, [N, 133] for scores
        keypoints_output = helper.make_tensor_value_info('final_keypoints', TensorProto.FLOAT, [None, None, 2])
        scores_output = helper.make_tensor_value_info('final_scores', TensorProto.FLOAT, [None, None])
        
        graph.output.extend([keypoints_output, scores_output])

# Usage Functions
def create_end_to_end_rtmpose_model(backbone_path, output_path, simcc_split_ratio=2.0, input_size=(256, 192)):
    """
    CORRECT function based on your model analysis
    """
    converter = RTMPoseEndToEndConverter(
        simcc_split_ratio=simcc_split_ratio,
        model_input_size=input_size
    )
    return converter.convert_to_end_to_end(backbone_path, output_path)

def test_end_to_end_model(model_path, batch_size=2):
    """Test the corrected model"""
    import onnxruntime as ort
    
    print(f"üß™ Testing corrected model: {model_path}")
    
    # Use your actual batch size from diagnostic
    test_images = np.random.randn(batch_size, 3, 256, 192).astype(np.float32)
    test_centers = np.random.randn(batch_size, 2).astype(np.float32) * 100 + 128
    test_scales = np.random.randn(batch_size, 2).astype(np.float32) * 50 + 200
    
    session = ort.InferenceSession(model_path, providers=['CPUExecutionProvider'])
    
    outputs = session.run(
        ["final_keypoints", "final_scores"],
        {
            "input": test_images,
            "centers": test_centers,
            "scales": test_scales
        }
    )
    
    final_keypoints, final_scores = outputs
    
    print("‚úÖ Test successful!")
    print(f"   Input: images {test_images.shape}, centers {test_centers.shape}, scales {test_scales.shape}")
    print(f"   Output: keypoints {final_keypoints.shape}, scores {final_scores.shape}")
    print(f"   Expected: keypoints ({batch_size}, 133, 2), scores ({batch_size}, 133)")
    
    return final_keypoints, final_scores

if __name__ == "__main__":
    try:
        print("üöÄ Converting RTMPose model (CORRECTED VERSION based on diagnostic)...")
        
        end_to_end_model = create_end_to_end_rtmpose_model(
            backbone_path="rtmpose_backbone.onnx",  # Your model path
            output_path="rtmpose_end_to_end_corrected.onnx",
            simcc_split_ratio=2.0,
            input_size=(256, 192)
        )
        
        print("üß™ Testing corrected model...")
        test_end_to_end_model(end_to_end_model, batch_size=2)
        
        print("üéâ SUCCESS! Corrected RTMPose end-to-end model works!")
        print()
        print("üîß What was fixed:")
        print("   ‚Ä¢ Element counts maintained: [N*K,2] -> [N,K,2] ‚úì")
        print("   ‚Ä¢ Proper reshape dimensions: 266*2=532 -> [2,133,2]=532 ‚úì")  
        print("   ‚Ä¢ All masking preserves [N*K] -> [N,K] element counts ‚úì")
        print("   ‚Ä¢ No more tensor size mismatches ‚úì")
        print()
        print("üìù Usage in your inference:")
        print("   import onnxruntime as ort")
        print("   session = ort.InferenceSession('rtmpose_end_to_end_corrected.onnx')")
        print("   keypoints, scores = session.run(['final_keypoints', 'final_scores'], {")
        print("       'input': batch_images,      # [N, 3, H, W]")
        print("       'centers': batch_centers,   # [N, 2]") 
        print("       'scales': batch_scales      # [N, 2]")
        print("   })")
        print("   # Results: keypoints[N, 133, 2], scores[N, 133]")
        print()
        print("üî• This CORRECTLY replaces your entire postprocess() workflow!")
        
    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        
        print("\nüí° If this still fails:")
        print("   1. Verify your model path is correct")
        print("   2. Check input/output names match your model")
        print("   3. Share the new error message if different")

"""
üéØ CORRECTED USAGE BASED ON YOUR DIAGNOSTIC:

Your model: simcc_x(N,133,384), simcc_y(N,133,512) 

# Convert your model:
create_end_to_end_rtmpose_model(
    "your_rtmpose_model.onnx",         # Your existing model  
    "rtmpose_end_to_end.onnx",         # Output end-to-end model
    simcc_split_ratio=2.0,             # Your SIMCC split ratio
    input_size=(256, 192)              # Your input size (W, H)
)

# New inference (replaces your entire workflow):
import onnxruntime as ort
session = ort.InferenceSession("rtmpose_end_to_end.onnx")

final_keypoints, final_scores = session.run(
    ["final_keypoints", "final_scores"],
    {
        "input": batch_images,      # [N, 3, H, W] - same as before
        "centers": batch_centers,   # [N, 2] - same as you use now  
        "scales": batch_scales      # [N, 2] - same as you use now
    }
)

# Results: keypoints[N, 133, 2], scores[N, 133] 
# Identical to your postprocess() function but ~30-50% faster!
"""
